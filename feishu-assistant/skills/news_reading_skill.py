"""
æ–°é—»ç²¾è¯»æŠ€èƒ½ - æ¯å¤©è·å–çº½çº¦æ—¶æŠ¥å’Œç»æµå­¦äººç²¾é€‰æ–°é—»
ç”Ÿæˆè‹±æ–‡åŸæ–‡ + é‡ç‚¹å•è¯ + å¥å­è®²è§£
"""
import os
import json
import asyncio
import httpx
from datetime import datetime
from typing import Dict, Any, List, Optional
from .base_skill import BaseSkill, SkillResult

# é£ä¹¦æ–‡æ¡£ API
LARK_DOC_API = "https://open.feishu.cn/open-apis/doc/v1"


class NewsReadingSkill(BaseSkill):
    """æ–°é—»ç²¾è¯»æŠ€èƒ½"""

    name = "news_reading"
    description = "è·å–çº½çº¦æ—¶æŠ¥å’Œç»æµå­¦äººç²¾é€‰æ–°é—»ï¼Œæä¾›è‹±æ–‡åŸæ–‡å’Œä¸­æ–‡è®²è§£"

    # ç±»çº§åˆ«ç¼“å­˜
    _cache: Dict[str, Any] = {}
    _cache_date: str = ""

    # NYT API (éœ€è¦ API key)
    NYT_API_KEY = os.environ.get("NYT_API_KEY", "")
    # Economist (ç½‘é¡µæŠ“å–)
    ECONOMIST_URL = "https://www.economist.com"

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.kimi_api_key = config.get("kimi_api_key") if config else os.environ.get("KIMI_API_KEY")
        self.feishu_app_id = os.environ.get("FEISHU_APP_ID")
        self.feishu_app_secret = os.environ.get("FEISHU_APP_SECRET")
        # ç«å±±å¼•æ“ API å¯†é’¥
        self.volcengine_access_key = os.environ.get("VOLCENGINE_ACCESS_KEY", "pOzMLb-Ez8AvBJ1Ym47m_Fk2l6ULzzRC")
        self.volcengine_secret_key = os.environ.get("VOLCENGINE_SECRET_KEY", "iq-Pa3WVvd4kALTYdiCH48L4n9HqVIX7")
        self.volcengine_app_id = os.environ.get("VOLCENGINE_APP_ID", "5884074284")

    async def execute(self, action: str = "fetch", **kwargs) -> SkillResult:
        """æ‰§è¡Œæ–°é—»è·å–"""
        if action == "fetch" or action == "daily":
            return await self.fetch_daily_news()
        elif action == "test":
            return await self.test_fetch()
        else:
            return SkillResult(
                success=False,
                message=f"æœªçŸ¥æ“ä½œ: {action}"
            )

    async def test_fetch(self) -> SkillResult:
        """æµ‹è¯•æ–°é—»è·å–"""
        try:
            # æµ‹è¯•è·å–æ–°é—»
            news_list = await self.fetch_nyt_news()
            return SkillResult(
                success=True,
                message=f"æµ‹è¯•æˆåŠŸï¼Œè·å–åˆ° {len(news_list)} æ¡æ–°é—»"
            )
        except Exception as e:
            return SkillResult(
                success=False,
                message=f"æµ‹è¯•å¤±è´¥: {str(e)}"
            )

    async def fetch_daily_news(self, use_cache: bool = True) -> SkillResult:
        """è·å–æ¯æ—¥æ–°é—»ç²¾è¯»

        Args:
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆå½“å¤©å†…è¿”å›ç›¸åŒå†…å®¹ï¼‰
        """
        from datetime import datetime
        today = datetime.now().strftime("%Y-%m-%d")

        # æ£€æŸ¥ç¼“å­˜
        if use_cache and NewsReadingSkill._cache_date == today:
            cached = NewsReadingSkill._cache.get("result")
            if cached:
                print("ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„æ–°é—»ç²¾è¯»")
                return cached

        try:
            all_news = []

            # 1. è·å–çº½çº¦æ—¶æŠ¥æ–°é—»
            print("ğŸ“° è·å–çº½çº¦æ—¶æŠ¥æ–°é—»...")
            nyt_news = await self.fetch_nyt_news()
            all_news.extend(nyt_news)

            # 2. è·å–ç»æµå­¦äººæ–°é—»
            print("ğŸ“° è·å–ç»æµå­¦äººæ–°é—»...")
            economist_news = await self.fetch_economist_news()
            all_news.extend(economist_news)

            if not all_news:
                return SkillResult(
                    success=False,
                    message="æœªè·å–åˆ°ä»»ä½•æ–°é—»"
                )

            # 3. ä½¿ç”¨ LLM ç”Ÿæˆç²¾è¯»å†…å®¹
            print(f"ğŸ“ ç”Ÿæˆ {len(all_news)} ç¯‡æ–‡ç« çš„ç²¾è¯»å†…å®¹...")
            readings = await self.generate_readings(all_news)

            # Debug: æ£€æŸ¥ç”Ÿæˆçš„ readings
            # 4. ç”Ÿæˆæ’­å®¢éŸ³é¢‘
            print("ğŸ™ï¸ ç”Ÿæˆæ’­å®¢éŸ³é¢‘...")
            podcast_url = await self.generate_podcast(readings)

            # 5. åˆ›å»ºé£ä¹¦æ–‡æ¡£
            print("ğŸ“„ åˆ›å»ºé£ä¹¦æ–‡æ¡£...")
            doc_url = await self.create_feishu_document(readings, podcast_url)

            # 6. å‘é€é€šçŸ¥
            message = f"ğŸ“° æ¯æ—¥æ–°é—»ç²¾è¯»å·²ç”Ÿæˆ\n\n"
            for i, r in enumerate(readings, 1):
                message += f"{i}. {r['title']}\n"

            message += f"\nğŸ“„ æ–‡æ¡£é“¾æ¥: {doc_url}"
            if podcast_url:
                message += f"\nğŸ™ï¸ æ’­å®¢é“¾æ¥: {podcast_url}"

            # ä¿å­˜åˆ°ç¼“å­˜
            result = SkillResult(
                success=True,
                message=message
            )
            NewsReadingSkill._cache_date = today
            NewsReadingSkill._cache["result"] = result
            print("ğŸ’¾ å·²ä¿å­˜åˆ°ç¼“å­˜")

            return result

        except Exception as e:
            import traceback
            traceback.print_exc()
            return SkillResult(
                success=False,
                message=f"è·å–æ–°é—»å¤±è´¥: {str(e)}"
            )

    async def fetch_nyt_news(self) -> List[Dict]:
        """è·å–å½“å¤©æ–°é—» - ä½¿ç”¨å¯é çš„æ•°æ®æº"""
        news_list = []
        today = datetime.now().strftime("%Y-%m-%d")

        print("å¼€å§‹è·å–å®æ—¶æ–°é—»...")

        # æ–¹æ³•1: BBC News RSS
        try:
            print("å°è¯• BBC News...")
            news_list = await self._fetch_from_bbc_news()
            if news_list:
                print(f"BBC News è·å–åˆ° {len(news_list)} æ¡")
        except Exception as e:
            print(f"BBC News è·å–å¤±è´¥: {e}")

        # æ–¹æ³•2: Reuters RSS
        if not news_list:
            try:
                print("å°è¯• Reuters...")
                news_list = await self._fetch_from_reuters_news()
                if news_list:
                    print(f"Reuters è·å–åˆ° {len(news_list)} æ¡")
            except Exception as e:
                print(f"Reuters è·å–å¤±è´¥: {e}")

        # æ–¹æ³•3: Al Jazeera RSS
        if not news_list:
            try:
                print("å°è¯• Al Jazeera...")
                news_list = await self._fetch_from_aljazeera_news()
                if news_list:
                    print(f"Al Jazeera è·å–åˆ° {len(news_list)} æ¡")
            except Exception as e:
                print(f"Al Jazeera è·å–å¤±è´¥: {e}")

        # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not news_list:
            print("è­¦å‘Š: æ‰€æœ‰æ–°é—»æºéƒ½è·å–å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []

        # è·å–æ–‡ç« æ­£æ–‡å†…å®¹
        for news in news_list:
            if news.get("url") and not news.get("content"):
                try:
                    content = await self.fetch_article_content(news["url"])
                    if content:
                        news["content"] = content
                except Exception as e:
                    print(f"è·å–æ–‡ç« å†…å®¹å¤±è´¥: {e}")

        return news_list[:3]

    async def _fetch_from_bbc_news(self) -> List[Dict]:
        """ä» BBC News è·å–æ–°é—»"""
        news_list = []
        try:
            async with httpx.AsyncClient() as client:
                url = "http://feeds.bbci.co.uk/news/world/rss.xml"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = await client.get(url, headers=headers, timeout=15)

                if resp.status_code == 200:
                    import xml.etree.ElementTree as ET
                    root = ET.fromstring(resp.text.encode('utf-8'))
                    for item in root.findall(".//item")[:5]:
                        title = item.findtext("title", "")
                        link = item.findtext("link", "")
                        desc = item.findtext("description", "")
                        import re
                        desc = re.sub(r'<[^>]+>', '', desc) if desc else ""

                        if title and link:
                            news_list.append({
                                "source": "BBC News",
                                "title": title,
                                "abstract": desc[:500] if desc else "",
                                "url": link,
                                "published_date": datetime.now().strftime("%Y-%m-%d")
                            })
        except Exception as e:
            print(f"BBC News error: {e}")

        return news_list

    async def _fetch_from_reuters_news(self) -> List[Dict]:
        """ä» Reuters è·å–æ–°é—»"""
        news_list = []
        try:
            async with httpx.AsyncClient() as client:
                url = "https://www.reutersagency.com/feed/?best-topics=business-finance"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = await client.get(url, headers=headers, timeout=15)

                if resp.status_code == 200:
                    import xml.etree.ElementTree as ET
                    try:
                        root = ET.fromstring(resp.text.encode('utf-8'))
                    except:
                        return news_list
                    for item in root.findall(".//item")[:5]:
                        title = item.findtext("title", "")
                        link = item.findtext("link", "")
                        desc = item.findtext("description", "")
                        import re
                        desc = re.sub(r'<[^>]+>', '', desc) if desc else ""

                        if title and link:
                            news_list.append({
                                "source": "Reuters",
                                "title": title,
                                "abstract": desc[:500] if desc else "",
                                "url": link,
                                "published_date": datetime.now().strftime("%Y-%m-%d")
                            })
        except Exception as e:
            print(f"Reuters error: {e}")

        return news_list

    async def _fetch_from_aljazeera_news(self) -> List[Dict]:
        """ä» Al Jazeera è·å–æ–°é—»"""
        news_list = []
        try:
            async with httpx.AsyncClient() as client:
                url = "https://www.aljazeera.com/xml/rss/all.xml"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = await client.get(url, headers=headers, timeout=15)

                if resp.status_code == 200:
                    import xml.etree.ElementTree as ET
                    root = ET.fromstring(resp.text.encode('utf-8'))
                    for item in root.findall(".//item")[:5]:
                        title = item.findtext("title", "")
                        link = item.findtext("link", "")
                        desc = item.findtext("description", "")
                        import re
                        desc = re.sub(r'<[^>]+>', '', desc) if desc else ""

                        if title and link:
                            news_list.append({
                                "source": "Al Jazeera",
                                "title": title,
                                "abstract": desc[:500] if desc else "",
                                "url": link,
                                "published_date": datetime.now().strftime("%Y-%m-%d")
                            })
        except Exception as e:
            print(f"Al Jazeera error: {e}")

        return news_list

    def get_default_nyt_news(self) -> List[Dict]:
        """é¢„è®¾çº½çº¦æ—¶æŠ¥æ–°é—»ï¼ˆå½“ API ä¸å¯ç”¨æ—¶ï¼‰"""
        return [
            {
                "source": "çº½çº¦æ—¶æŠ¥",
                "title": "The Global Economy Shows Resilience Amid Uncertainty",
                "abstract": "Despite ongoing challenges, the global economy demonstrates surprising strength as inflation cools and employment remains robust.",
                "content": """The global economy is showing remarkable resilience in the face of unprecedented challenges, according to the latest economic data released by major central banks around the world. Despite lingering concerns about inflation, geopolitical tensions, and supply chain disruptions, key indicators point to a economy that continues to expand at a sustainable pace.

Consumer spending, which accounts for roughly 70% of economic activity in developed economies, has remained robust even as prices have risen. Retail sales data from the past quarter exceeded analyst expectations, suggesting that households are adapting to the new price environment more quickly than anticipated. This resilience is particularly notable given the significant interest rate increases implemented by central banks over the past two years.

The labor market continues to demonstrate remarkable strength, with unemployment rates hovering near historic lows across most developed economies. Job creation has remained consistently strong, and wage growth has begun to moderate from its peak levels, creating what many economists describe as a "soft landing" scenario. This balance between employment growth and cooling wage pressures is exactly what policymakers have been hoping to achieve.

Central banks are now navigating a delicate path between supporting growth and containing inflation. While most major central banks have paused or slowed their rate-hiking cycles, they remain vigilant about the inflation outlook. The recent stabilization of energy prices has provided welcome relief, but services inflation remainssticky in some regions.

Looking ahead, economists surveyed by major research institutions expect moderate but positive growth in the coming quarters. The consensus view is that the global economy will avoid a recession, though the path to normalization will likely be uneven across different regions and sectors.""",
                "url": "https://www.nytimes.com",
                "published_date": datetime.now().strftime("%Y-%m-%d")
            },
            {
                "source": "çº½çº¦æ—¶æŠ¥",
                "title": "Climate Summit Reaches Historic Agreement",
                "abstract": "World leaders commit to ambitious carbon reduction targets in landmark climate accord.",
                "content": """In a landmark decision that climate scientists are calling a turning point in the global response to climate change, representatives from over 190 countries have agreed to the most ambitious set of carbon reduction targets in history. The agreement, reached after two weeks of intense negotiations at the Global Climate Summit, sets binding commitments to phase out fossil fuels and accelerate the transition to renewable energy.

The accord establishes a comprehensive framework for reducing greenhouse gas emissions, with industrialized nations committing to achieving net-zero emissions by 2050, while developing countries will receive substantial financial support to help them transition to clean energy sources. The agreement includes a landmark provision establishing a new fund to help vulnerable nations cope with the impacts of climate change that are already occurring.

Key provisions of the agreement include: a commitment to triple renewable energy capacity globally by 2035; a phase-down schedule for coal-fired power plants; new regulations on methane emissions from oil and gas operations; and a framework for carbon pricing that will apply to major emitting industries. The agreement also establishes transparent monitoring mechanisms to ensure countries meet their commitments.

Developing nations welcomed the financial support package, which includes $100 billion annually in climate finance from developed countries. The funds will be directed toward building renewable energy infrastructure, adapting to climate impacts, and supporting a just transition for workers in fossil fuel industries.

Environmental groups, while noting the agreement's historic significance, emphasized that the hard work of implementation lies ahead. "This agreement gives us the roadmap," said one prominent climate activist, "but now we must deliver on these commitments at scale and speed.""",
                "url": "https://www.nytimes.com",
                "published_date": datetime.now().strftime("%Y-%m-%d")
            },
            {
                "source": "çº½çº¦æ—¶æŠ¥",
                "title": "Technology Giants Report Strong Quarterly Earnings",
                "abstract": "Major tech companies exceed expectations as AI investments begin to pay off.",
                "content": """The largest technology companies in the world reported stronger-than-expected quarterly earnings this week, with AI-related services emerging as a key growth driver for the first time. The results marked a significant turning point for the sector, as years of investment in artificial intelligence infrastructure began to translate into measurable revenue growth.

Cloud computing divisions, which have been at the forefront of companies' AI strategies, reported particularly strong performance. Enterprise customers are increasingly adopting AI-powered tools for data analysis, customer service automation, and software development. This adoption is driving higher average contract values and improving retention rates across major cloud platforms.

The earnings reports sent stock prices soaring in after-hours trading, with some companies gaining over 10% on the news. Analysts noted that the results suggested the technology sector's transition to an AI-focused business model is progressing faster than many had anticipated. Revenue from AI-related services now accounts for a meaningful and growing portion of total company revenues.

Looking ahead, company executives expressed optimism about continued AI-driven growth. "We are just beginning to see the transformative potential of artificial intelligence across every industry," said one CEO during the earnings call. The companies announced plans to increase capital expenditure on AI infrastructure, signaling confidence in continued strong demand.

However, some analysts cautioned that the AI boom comes with risks. Competition is intensifying, regulatory scrutiny is increasing, and the massive investments required to maintain leadership in AI could pressure margins over time. Despite these concerns, the overall sentiment in the market remains decidedly bullish on the technology sector's near-term prospects.""",
                "url": "https://www.nytimes.com",
                "published_date": datetime.now().strftime("%Y-%m-%d")
            }
        ]

    async def fetch_economist_news(self) -> List[Dict]:
        """è·å–å•†ä¸š/è´¢ç»æ–°é—»"""
        news_list = []

        print("å¼€å§‹è·å–è´¢ç»æ–°é—»...")

        # æ–¹æ³•1: CNBC RSS
        try:
            print("å°è¯• CNBC...")
            news_list = await self._fetch_from_cnbc_news()
            if news_list:
                print(f"CNBC è·å–åˆ° {len(news_list)} æ¡")
        except Exception as e:
            print(f"CNBC è·å–å¤±è´¥: {e}")

        # æ–¹æ³•2: Yahoo Finance
        if not news_list:
            try:
                print("å°è¯• Yahoo Finance...")
                news_list = await self._fetch_from_yahoo_news()
                if news_list:
                    print(f"Yahoo Finance è·å–åˆ° {len(news_list)} æ¡")
            except Exception as e:
                print(f"Yahoo Finance è·å–å¤±è´¥: {e}")

        # æ–¹æ³•3: CNBC Technology
        if not news_list:
            try:
                print("å°è¯• TechCrunch...")
                news_list = await self._fetch_from_techcrunch_news()
                if news_list:
                    print(f"TechCrunch è·å–åˆ° {len(news_list)} æ¡")
            except Exception as e:
                print(f"TechCrunch è·å–å¤±è´¥: {e}")

        # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not news_list:
            print("è­¦å‘Š: æ‰€æœ‰è´¢ç»æ–°é—»æºéƒ½è·å–å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []

        # è·å–æ–‡ç« æ­£æ–‡å†…å®¹
        for news in news_list:
            if news.get("url") and not news.get("content"):
                try:
                    content = await self.fetch_article_content(news["url"])
                    if content:
                        news["content"] = content
                except Exception as e:
                    print(f"è·å–æ–‡ç« å†…å®¹å¤±è´¥: {e}")

        return news_list[:3]

    async def _fetch_from_cnbc_news(self) -> List[Dict]:
        """ä» CNBC è·å–æ–°é—»"""
        news_list = []
        try:
            async with httpx.AsyncClient() as client:
                url = "https://www.cnbc.com/id/100003114/device/rss/rss.html"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = await client.get(url, headers=headers, timeout=15)

                if resp.status_code == 200:
                    import xml.etree.ElementTree as ET
                    root = ET.fromstring(resp.text.encode('utf-8'))
                    for item in root.findall(".//item")[:5]:
                        title = item.findtext("title", "")
                        link = item.findtext("link", "")
                        desc = item.findtext("description", "")
                        import re
                        desc = re.sub(r'<[^>]+>', '', desc) if desc else ""

                        if title and link:
                            news_list.append({
                                "source": "CNBC",
                                "title": title,
                                "abstract": desc[:500] if desc else "",
                                "url": link,
                                "published_date": datetime.now().strftime("%Y-%m-%d")
                            })
        except Exception as e:
            print(f"CNBC error: {e}")

        return news_list

    async def _fetch_from_yahoo_news(self) -> List[Dict]:
        """ä» Yahoo Finance è·å–æ–°é—»"""
        news_list = []
        try:
            async with httpx.AsyncClient() as client:
                url = "https://finance.yahoo.com/news/rssindex"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = await client.get(url, headers=headers, timeout=15)

                if resp.status_code == 200:
                    import xml.etree.ElementTree as ET
                    root = ET.fromstring(resp.text.encode('utf-8'))
                    for item in root.findall(".//item")[:5]:
                        title = item.findtext("title", "")
                        link = item.findtext("link", "")
                        desc = item.findtext("description", "")
                        import re
                        desc = re.sub(r'<[^>]+>', '', desc) if desc else ""

                        if title and link:
                            news_list.append({
                                "source": "Yahoo Finance",
                                "title": title,
                                "abstract": desc[:500] if desc else "",
                                "url": link,
                                "published_date": datetime.now().strftime("%Y-%m-%d")
                            })
        except Exception as e:
            print(f"Yahoo Finance error: {e}")

        return news_list

    async def _fetch_from_techcrunch_news(self) -> List[Dict]:
        """ä» TechCrunch è·å–æ–°é—»"""
        news_list = []
        try:
            async with httpx.AsyncClient() as client:
                url = "https://techcrunch.com/feed/"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = await client.get(url, headers=headers, timeout=15)

                if resp.status_code == 200:
                    import xml.etree.ElementTree as ET
                    root = ET.fromstring(resp.text.encode('utf-8'))
                    for item in root.findall(".//item")[:5]:
                        title = item.findtext("title", "")
                        link = item.findtext("link", "")
                        desc = item.findtext("description", "")
                        import re
                        desc = re.sub(r'<[^>]+>', '', desc) if desc else ""

                        if title and link:
                            news_list.append({
                                "source": "TechCrunch",
                                "title": title,
                                "abstract": desc[:500] if desc else "",
                                "url": link,
                                "published_date": datetime.now().strftime("%Y-%m-%d")
                            })
        except Exception as e:
            print(f"TechCrunch error: {e}")

        return news_list

    async def _fetch_from_economist_rss(self) -> List[Dict]:
        """ä» Economist RSS è·å–æ–°é—»"""
        news_list = []
        try:
            async with httpx.AsyncClient() as client:
                url = "https://www.economist.com/rss"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = await client.get(url, headers=headers, timeout=15)

                if resp.status_code == 200:
                    import xml.etree.ElementTree as ET
                    root = ET.fromstring(resp.text)
                    for item in root.findall(".//item")[:3]:
                        title = item.findtext("title", "")
                        link = item.findtext("link", "")
                        desc = item.findtext("description", "")
                        import re
                        desc = re.sub(r'<[^>]+>', '', desc) if desc else ""

                        if title and link:
                            news_list.append({
                                "source": "The Economist",
                                "title": title,
                                "abstract": desc[:500],
                                "url": link,
                                "published_date": datetime.now().strftime("%Y-%m-%d")
                            })
        except Exception as e:
            print(f"Economist RSS error: {e}")

        return news_list

    async def _fetch_business_news(self) -> List[Dict]:
        """ä» Bing è·å–å•†ä¸šæ–°é—»"""
        news_list = []
        try:
            async with httpx.AsyncClient() as client:
                url = "https://www.bing.com/news/search?q=business+economy+technology&form=QBLH"
                headers = {"User-Agent": "Mozilla/5.0"}
                resp = await client.get(url, headers=headers, timeout=15)

                # ç”±äº Bing é¡µé¢æ˜¯åŠ¨æ€åŠ è½½çš„ï¼Œè¿™é‡Œè¿”å›ç©º
                # å®é™…å¯ä»¥ç”¨ Bing News API
                pass
        except Exception as e:
            print(f"Business news error: {e}")

        return news_list

    async def fetch_article_content(self, url: str) -> str:
        """è·å–æ–‡ç« æ­£æ–‡å†…å®¹"""
        try:
            async with httpx.AsyncClient() as client:
                headers = {
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
                }
                resp = await client.get(url, headers=headers, timeout=15, follow_redirects=True)

                if resp.status_code == 200:
                    # ç®€å•æå–æ–‡ç« å†…å®¹ï¼ˆå®é™…éœ€è¦æ›´å¤æ‚çš„è§£æï¼‰
                    # å°è¯•è·å– meta description æˆ–æ–‡ç« å†…å®¹
                    import re
                    text = resp.text

                    # å°è¯•è·å– meta description
                    desc_match = re.search(r'<meta[^>]*name=["\']description["\'][^>]*content=["\']([^"\']+)["\']', text, re.I)
                    if desc_match:
                        return desc_match.group(1)

                    # å°è¯•è·å– og:description
                    og_match = re.search(r'<meta[^>]*property=["\']og:description["\'][^>]*content=["\']([^"\']+)["\']', text, re.I)
                    if og_match:
                        return og_match.group(1)

        except Exception as e:
            print(f"è·å–æ–‡ç« å†…å®¹å¤±è´¥: {e}")

        return ""

    def get_default_economist_news(self) -> List[Dict]:
        """é¢„è®¾ç»æµå­¦äººæ–°é—»"""
        return [
            {
                "source": "ç»æµå­¦äºº",
                "title": "The World in 2026: A Special Report",
                "abstract": "Our annual forecast examines the key trends shaping the global economy, politics and technology.",
                "content": """The global economy enters 2026 at an inflection point. After years of disruption, adjustment, and occasional crisis, a new equilibrium is emergingâ€”one shaped by technological transformation, geopolitical realignment, and evolving attitudes toward government intervention in markets.

The past year has seen artificial intelligence move from experimental deployments to production-scale implementations across virtually every industry. What began as a wave of enthusiasm for large language models has matured into a more pragmatic appreciation of what AI can and cannot do. Companies are now measuring returns on their AI investments, and the results are encouraging but uneven. While some sectorsâ€”particularly software, financial services, and healthcareâ€”have seen dramatic productivity gains, others have struggled to integrate these new tools into existing workflows.

Geopolitical tensions continue to reshape global trade patterns. The relationship between the United States and China remains the defining bilateral relationship of the era, with both sides taking careful steps to manage competition while avoiding catastrophic confrontation. Meanwhile, a new sense of strategic purpose has emerged among middle powers, who are increasingly seeking to hedge their bets between the great powers rather than align definitively with either.

In Europe, the economic picture has brightened somewhat, though structural challenges remain. The continent's efforts to build indigenous technological capabilitiesâ€”particularly in semiconductors and clean energyâ€”have begun to bear fruit. Yet Europe continues to struggle with slow growth and demographic headwinds that will shape its trajectory for decades to come.

The big question for the year ahead is whether the current period of moderate growth and easing inflation will prove sustainable, or whether new shocksâ€”a further escalation of geopolitical conflict, a resurgence of inflation, or a financial-market correctionâ€”will derail the recovery. The odds may favor continued stability, but the margin for error remains thin.""",
                "url": "https://www.economist.com",
                "published_date": datetime.now().strftime("%Y-%m-%d")
            },
            {
                "source": "ç»æµå­¦äºº",
                "title": "The Return of Industrial Policy",
                "abstract": "Governments worldwide are rediscovering the benefits of directing economic activity.",
                "content": """After decades in which the consensus view held that markets, not governments, should decide which industries succeed, industrial policy is back. Across the rich world, governments are pouring subsidies into semiconductors, electric vehicles, batteries, and renewable energy. In the United States, the Inflation Reduction Act has committed nearly $400 billion to clean-energy manufacturing. In Europe, the Green Deal Industrial Plan aims to capture a quarter of global battery production by 2030. Japan and South Korea continue to lavish support on their chipmakers.

This represents a dramatic shift in economic philosophy. For much of the past four decades, the prevailing wisdom held that industrial policy wasInefficient, prone to capture by vested interests, and better suited to command economies than market-based ones. The collapse of Soviet-style planning seemed to confirm these doubts. The dominance of American tech giants, built on entrepreneurial dynamism rather than state direction, appeared to prove that governments should stick to basics: property rights, competition policy, and macroeconomic stability.

What changed? The pandemic exposed the fragility of global supply chains. The war in Ukraine demonstrated the geopolitical risks of energy dependence. And above all, China's riseâ€”built explicitly on state-led industrial policyâ€”challenged the assumption that market forces alone could deliver technological leadership. The logic now is simple: if China can use subsidies to dominate solar panels and batteries, why should the West play by different rules?

The risks are real. Subsidies can distort markets, entrench incumbents, and provoke retaliation. The history of industrial policy is littered with failuresâ€”think of Europe's attempts to build a rival to Boeing or America's support for Solyndra. Yet the potential rewards are also substantial. If the current wave of industrial policy succeeds, it could generate new industries, jobs, and strategic capabilities. If it fails, it will leave behind a trail of debt and disappointed expectations.""",
                "url": "https://www.economist.com",
                "published_date": datetime.now().strftime("%Y-%m-%d")
            },
            {
                "source": "ç»æµå­¦äºº",
                "title": "Artificial Intelligence: The Next Chapter",
                "abstract": "As AI models become more capable, the debate shifts from what they can do to how they should be governed.",
                "content": """The conversation about artificial intelligence has shifted dramatically over the past year. Only recently, the dominant theme was awe at what these systems could doâ€”their ability to write poetry, debug code, and pass professional exams seemed to herald a technological transformation unlike anything since the internet. Today, the conversation is increasingly about governance, regulation, and control.

This shift reflects both the pace of AI deployment and growing awareness of the risks. As companies integrate large language models into customer service, content moderation, hiring decisions, and medical diagnosis, the potential for harm has become concrete rather than hypothetical. Bias in AI systems has led to discriminatory outcomes. Hallucinations have caused real-world problems when users relied on AI-generated legal briefs or medical advice. And the prospect of more powerful systemsâ€”potentially achieving artificial general intelligence within this decadeâ€”has prompted warnings from some of the very researchers who built these tools.

Regulators around the world are responding. The European Union's AI Act, which entered into force last year, establishes a risk-based framework for AI governance, with strict requirements for high-risk applications and transparency obligations for general-purpose models. The United States has taken a more sector-specific approach, issuing executive orders on AI safety and security while encouraging industry standards. China has moved quickly to regulate generative AI, requiring registration and content review for popular services.

For businesses, the regulatory landscape creates both costs and opportunities. Compliance with new rules will require investment in safety testing, documentation, and human oversight. But companies that successfully navigate the regulatory environment may find themselves with significant competitive advantagesâ€”particularly in industries like healthcare and finance where trust is paramount.

The fundamental question remains unresolved: how should societies balance the transformative potential of AI against the risks it poses? The answer will shape not just the technology industry but the broader economy and society for decades to come. What is clear is that the era of unconstrained experimentation is ending; the era of AI governance is just beginning.""",
                "url": "https://www.economist.com",
                "published_date": datetime.now().strftime("%Y-%m-%d")
            }
        ]

    async def generate_readings(self, news_list: List[Dict]) -> List[Dict]:
        """ä½¿ç”¨ LLM ç”Ÿæˆç²¾è¯»å†…å®¹"""
        readings = []

        for news in news_list:
            try:
                reading = await self.generate_single_reading(news)
                readings.append(reading)
            except Exception as e:
                print(f"ç”Ÿæˆç²¾è¯»å¤±è´¥: {e}")
                continue

        return readings

    async def generate_single_reading(self, news: Dict) -> Dict:
        """ç”Ÿæˆå•ç¯‡æ–‡ç« çš„ç²¾è¯»å†…å®¹"""
        # è·å–æ–‡ç« åŸæ–‡å†…å®¹
        article_content = news.get("content", "") or news.get("abstract", "")

        prompt = f"""è¯·åˆ†æä»¥ä¸‹è‹±æ–‡æ–‡ç« ï¼Œç”Ÿæˆç²¾è¯»å†…å®¹ï¼š

æ ‡é¢˜: {news['title']}
æ¥æº: {news['source']}
åŸæ–‡å†…å®¹: {article_content}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¿”å› JSONï¼š
{{
    "title": "è‹±æ–‡æ ‡é¢˜",
    "vocabulary": [
        {{"word": "å•è¯", "meaning": "ä¸­æ–‡å«ä¹‰"}},
        ...
    ],
    "key_sentences": [
        {{"english": "è‹±æ–‡å¥å­", "chinese": "ä¸­æ–‡ç¿»è¯‘", "explanation": "è®²è§£"}},
        ...
    ],
    "summary": "æ–‡ç« è¦ç‚¹æ€»ç»“ï¼ˆä¸­æ–‡ï¼‰"
}}

è¯·æ ¹æ®åŸæ–‡å†…å®¹é€‰æ‹©3-5ä¸ªé‡ç‚¹å•è¯å’Œ3ä¸ªå…³é”®å¥å­ã€‚
"""

        try:
            async with httpx.AsyncClient() as client:
                resp = await client.post(
                    "https://api.moonshot.cn/v1/chat/completions",
                    headers={"Authorization": f"Bearer {self.kimi_api_key}"},
                    json={
                        "model": "moonshot-v1-8k",
                        "messages": [
                            {"role": "user", "content": prompt}
                        ],
                        "temperature": 0.3
                    },
                    timeout=30
                )

                if resp.status_code == 200:
                    data = resp.json()
                    content = data["choices"][0]["message"]["content"]

                    # è§£æ JSON
                    import re
                    json_match = re.search(r'\{[\s\S]*\}', content)
                    if json_match:
                        reading_data = json.loads(json_match.group())
                        return {
                            "source": news["source"],
                            "title": news["title"],
                            "abstract": news["abstract"],
                            "content": article_content,  # ä¿ç•™åŸæ–‡
                            "url": news["url"],
                            **reading_data
                        }
        except Exception as e:
            print(f"LLM ç”Ÿæˆå¤±è´¥: {e}")

        # å¦‚æœå¤±è´¥ï¼Œè¿”å›ç®€åŒ–ç‰ˆæœ¬
        return {
            "source": news["source"],
            "title": news["title"],
            "abstract": news["abstract"],
            "content": article_content,  # ä¿ç•™åŸæ–‡
            "url": news["url"],
            "vocabulary": [],
            "key_sentences": [],
            "summary": news["abstract"]
        }

    async def create_feishu_document(self, readings: List[Dict], podcast_url: str = "") -> str:
        """åˆ›å»ºé£ä¹¦æ–‡æ¡£å¹¶å‘é€æ¶ˆæ¯"""
        try:
            token = await self.get_feishu_token()
            doc_url = ""
            doc_created = False

            if token:
                # å°è¯•åˆ›å»ºé£ä¹¦æ–‡æ¡£
                date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
                doc_title = f"æ¯æ—¥æ–°é—»ç²¾è¯» - {date_str}"
                doc_content = self._build_document_content(readings, podcast_url)
                doc_url = await self._create_feishu_doc_api(token, doc_title, doc_content)
                if doc_url and doc_url.startswith("http"):
                    doc_created = True

            # å‘é€å®Œæ•´å†…å®¹æ¶ˆæ¯
            result = await self._create_text_content(readings, doc_url)
            return result

        except Exception as e:
            print(f"åˆ›å»ºé£ä¹¦å†…å®¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return await self._create_text_content(readings, "")

    def _build_document_content(self, readings: List[Dict], podcast_url: str = "") -> str:
        """æ„å»ºé£ä¹¦æ–‡æ¡£å†…å®¹ (çº¯æ–‡æœ¬æ ¼å¼)"""
        lines = []

        # æ·»åŠ æ ‡é¢˜
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        lines.append(f"# ğŸ“° æ¯æ—¥æ–°é—»ç²¾è¯» - {date_str}")
        lines.append("")

        # æ·»åŠ æ’­å®¢é“¾æ¥
        if podcast_url:
            lines.append(f"ğŸ™ï¸ æ’­å®¢éŸ³é¢‘: {podcast_url}")
            lines.append("")

        lines.append("æ¥æºï¼šçº½çº¦æ—¶æŠ¥ + ç»æµå­¦äºº")
        lines.append("")
        lines.append(f"# ğŸ“° æ¯æ—¥æ–°é—»ç²¾è¯» - {date_str}")
        lines.append("")
        lines.append("æ¥æºï¼šçº½çº¦æ—¶æŠ¥ + ç»æµå­¦äºº")
        lines.append("")

        # éå†æ¯ç¯‡æ–‡ç« 
        for i, r in enumerate(readings, 1):
            lines.append(f"## {i}. {r.get('title', 'Untitled')}")
            lines.append(f"æ¥æº: {r.get('source', '')}")

            # åŸæ–‡/æ‘˜è¦
            content = r.get("content") or r.get("abstract", "")
            if content:
                lines.append(f"ğŸ“ åŸæ–‡:\n{content}")

            # å•è¯è¡¨
            vocab = r.get("vocabulary", [])
            if vocab:
                lines.append("ğŸ“š é‡ç‚¹å•è¯:")
                for v in vocab:
                    word = v.get("word", "")
                    meaning = v.get("meaning", "")
                    lines.append(f"  â€¢ {word}: {meaning}")
                lines.append("")

            # å…³é”®å¥å­
            sentences = r.get("key_sentences", [])
            if sentences:
                lines.append("ğŸ’¬ å…³é”®å¥å­:")
                for s in sentences:
                    eng = s.get("english", "")
                    chi = s.get("chinese", "")
                    exp = s.get("explanation", "")
                    lines.append(f"  â€¢ {eng}")
                    lines.append(f"    â†’ {chi}")
                    lines.append(f"    ğŸ’¡ {exp}")
                lines.append("")

            # æ€»ç»“
            summary = r.get("summary", "")
            if summary:
                lines.append(f"ğŸ“‹ æ€»ç»“:\n{summary}")

            lines.append("")
            lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            lines.append("")

        return "\n".join(lines)

    async def _create_feishu_doc_api(self, token: str, title: str, content: str) -> str:
        """è°ƒç”¨é£ä¹¦ API åˆ›å»ºæ–‡æ¡£"""
        try:
            # ä½¿ç”¨æ­£ç¡®çš„ docx API ç«¯ç‚¹
            url = "https://open.feishu.cn/open-apis/docx/v1/documents"
            headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }

            # å…ˆåˆ›å»ºç©ºæ–‡æ¡£
            payload = {"title": title}

            async with httpx.AsyncClient() as client:
                resp = await client.post(url, headers=headers, json=payload, timeout=30)
                print(f"åˆ›å»ºæ–‡æ¡£å“åº”: status={resp.status_code}, body={resp.text[:300]}")

                if resp.status_code == 200:
                    data = resp.json()
                    if data.get("code") == 0:
                        # ä¿®å¤: document_id åœ¨ data.document.document_id
                        doc_data = data.get("data", {}).get("document", {})
                        doc_id = doc_data.get("document_id") if isinstance(doc_data, dict) else None
                        if doc_id:
                            # ä½¿ç”¨æ­£ç¡®çš„æ–‡æ¡£é“¾æ¥æ ¼å¼
                            doc_url = f"https://my.feishu.cn/docx/{doc_id}"
                            # æ·»åŠ å†…å®¹åˆ°æ–‡æ¡£
                            await self._add_doc_content(token, doc_id, content)
                            return doc_url

            return ""

        except Exception as e:
            print(f"åˆ›å»ºé£ä¹¦æ–‡æ¡£å¤±è´¥: {e}")
            return ""

    async def _add_doc_content(self, token: str, doc_id: str, content: str):
        """å‘æ–‡æ¡£æ·»åŠ å†…å®¹"""
        try:
            # è·å–é¡µé¢å— ID
            url = f"https://open.feishu.cn/open-apis/docx/v1/documents/{doc_id}/blocks?page_size=1"
            headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }

            async with httpx.AsyncClient() as client:
                resp = await client.get(url, headers=headers, timeout=30)
                if resp.status_code == 200:
                    data = resp.json()
                    if data.get("code") == 0:
                        items = data.get("data", {}).get("items", [])
                        if items:
                            page_block_id = items[0].get("block_id")
                            # æ·»åŠ å†…å®¹
                            await self._write_text_to_doc(token, doc_id, page_block_id, content)

        except Exception as e:
            print(f"æ·»åŠ æ–‡æ¡£å†…å®¹å¤±è´¥: {e}")

    async def _write_text_to_doc(self, token: str, doc_id: str, page_block_id: str, content: str):
        """å†™å…¥æ–‡æœ¬å†…å®¹åˆ°æ–‡æ¡£"""
        try:
            url = f"https://open.feishu.cn/open-apis/docx/v1/documents/{doc_id}/blocks/{page_block_id}/children"

            # å°†å†…å®¹æŒ‰è¡Œåˆ†å‰²ï¼Œæ¯è¡Œä½œä¸ºä¸€ä¸ªæ–‡æœ¬å—
            lines = content.split('\n')
            children = []

            for line in lines[:100]:  # é™åˆ¶æœ€å¤š 100 è¡Œ
                line = line.rstrip()
                if not line:
                    continue

                # æ£€æµ‹æ˜¯å¦ä¸ºæ ‡é¢˜
                if line.startswith('# '):
                    # æ ‡é¢˜1 - block_type 3
                    children.append({
                        "block_type": 3,
                        "heading1": {"elements": [{"text_run": {"content": line[2:].strip()}}]}
                    })
                elif line.startswith('## '):
                    # æ ‡é¢˜2 - block_type 4
                    children.append({
                        "block_type": 4,
                        "heading2": {"elements": [{"text_run": {"content": line[3:].strip()}}]}
                    })
                elif line.startswith('### '):
                    # æ ‡é¢˜3 - block_type 5
                    children.append({
                        "block_type": 5,
                        "heading3": {"elements": [{"text_run": {"content": line[4:].strip()}}]}
                    })
                elif line.startswith('- ') or line.startswith('* '):
                    # æ— åºåˆ—è¡¨ - block_type 12
                    text = line[2:].strip()
                    children.append({
                        "block_type": 12,
                        "bullet": {"elements": [{"text_run": {"content": text}}]}
                    })
                elif line.startswith('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€'):
                    # åˆ†å‰²çº¿ - ä½¿ç”¨æ–‡æœ¬å—ä»£æ›¿
                    children.append({
                        "block_type": 2,
                        "text": {"elements": [{"text_run": {"content": "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"}}]}
                    })
                else:
                    # æ™®é€šæ–‡æœ¬ - block_type 2
                    if line:
                        children.append({
                            "block_type": 2,
                            "text": {"elements": [{"text_run": {"content": line}}]}
                        })

            if not children:
                return

            print(f"å‡†å¤‡å†™å…¥ {len(children)} ä¸ªå—åˆ°æ–‡æ¡£")

            # åˆ†æ‰¹å†™å…¥ï¼Œæ¯æ‰¹æœ€å¤š 50 ä¸ªå—
            batch_size = 50
            async with httpx.AsyncClient() as client:
                for i in range(0, len(children), batch_size):
                    batch = children[i:i+batch_size]
                    payload = {"children": batch}

                    resp = await client.post(url, headers={
                        "Authorization": f"Bearer {token}",
                        "Content-Type": "application/json"
                    }, json=payload, timeout=60)

                    print(f"å†™å…¥å†…å®¹å“åº”: status={resp.status_code}, body={resp.text[:200]}")

        except Exception as e:
            print(f"å†™å…¥æ–‡æ¡£å†…å®¹å¤±è´¥: {e}")

    async def _send_notification_message(self, readings: List[Dict], doc_url: str):
        """å‘é€é€šçŸ¥æ¶ˆæ¯åˆ°é£ä¹¦"""
        try:
            feishu_open_id = os.environ.get("FEISHU_USER_OPEN_ID")
            if not feishu_open_id:
                return

            # æ„å»ºç®€çŸ­é€šçŸ¥
            message = f"ğŸ“° æ¯æ—¥æ–°é—»ç²¾è¯»å·²ç”Ÿæˆ\n\n"
            for i, r in enumerate(readings, 1):
                message += f"{i}. {r.get('title', 'Untitled')}\n"

            if doc_url and doc_url.startswith("http"):
                message += f"\nğŸ“„ æ–‡æ¡£é“¾æ¥: {doc_url}"

            await self.send_feishu_message(feishu_open_id, message)

        except Exception as e:
            print(f"å‘é€é€šçŸ¥å¤±è´¥: {e}")

    async def _create_text_content(self, readings: List[Dict], doc_url: str = "") -> str:
        """æ„å»ºæ¶ˆæ¯å†…å®¹å¹¶å‘é€"""
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        title = f"ğŸ“° æ¯æ—¥æ–°é—»ç²¾è¯» - {date_str}"

        content = []
        content.append(title)
        content.append("")
        content.append("æ¥æºï¼šçº½çº¦æ—¶æŠ¥ + ç»æµå­¦äºº")
        content.append("ç”Ÿæˆæ—¶é—´ï¼š" + datetime.now().strftime("%Y-%m-%d %H:%M"))

        # æ·»åŠ é£ä¹¦æ–‡æ¡£é“¾æ¥
        if doc_url and doc_url.startswith("http"):
            content.append("")
            content.append(f"ğŸ“„ æ–‡æ¡£é“¾æ¥: {doc_url}")
        else:
            content.append("")
            content.append("ğŸ“„ è¯¦ç»†å†…å®¹è¯·æŸ¥çœ‹ä¸‹æ–¹ç²¾è¯»å†…å®¹")

        content.append("")
        content.append("=" * 40)

        for i, r in enumerate(readings, 1):
            content.append("")
            content.append(f"ã€{i}. {r.get('title', 'Untitled')}ã€‘")
            content.append(f"æ¥æº: {r.get('source', '')}")

            # åŸæ–‡
            text_content = r.get("content") or r.get("abstract", "")
            if text_content:
                content.append(f"ğŸ“ åŸæ–‡: {text_content}")

            # å•è¯è¡¨
            vocab = r.get("vocabulary", [])
            if vocab:
                content.append("")
                content.append("ğŸ“š é‡ç‚¹å•è¯:")
                for v in vocab:
                    content.append(f"  â€¢ {v.get('word', '')}: {v.get('meaning', '')}")

            # å…³é”®å¥å­
            sentences = r.get("key_sentences", [])
            if sentences:
                content.append("")
                content.append("ğŸ’¬ å…³é”®å¥å­:")
                for s in sentences:
                    content.append(f"  {s.get('english', '')}")
                    content.append(f"  â†’ {s.get('chinese', '')}")
                    content.append(f"  ğŸ’¡ {s.get('explanation', '')}")

            # æ€»ç»“
            if r.get("summary"):
                content.append("")
                content.append(f"ğŸ“‹ æ€»ç»“: {r.get('summary', '')}")

            content.append("")
            content.append("-" * 40)

        message_text = "\n".join(content)

        # æ³¨æ„ï¼šä¸å†ç›´æ¥å‘é€æ¶ˆæ¯ï¼Œç”± main_v2.py é€šè¿‡ SkillResult ç»Ÿä¸€å‘é€
        # é¿å…é‡å¤å‘é€ä¸¤æ¡æ¶ˆæ¯

        return message_text

    async def send_feishu_message(self, user_id: str, text: str) -> bool:
        """å‘é€é£ä¹¦æ¶ˆæ¯"""
        try:
            token = await self.get_feishu_token()
            if not token:
                print("å‘é€æ¶ˆæ¯: è·å– token å¤±è´¥")
                return False

            # é£ä¹¦æ¶ˆæ¯ API - receive_id_type éœ€è¦åœ¨ URL å‚æ•°ä¸­
            url = "https://open.feishu.cn/open-apis/im/v1/messages?receive_id_type=open_id"
            headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }

            payload = {
                "receive_id": user_id,
                "msg_type": "text",
                "content": json.dumps({"text": text})
            }

            async with httpx.AsyncClient() as client:
                resp = await client.post(url, headers=headers, json=payload, timeout=30)
                print(f"å‘é€æ¶ˆæ¯å“åº”: status={resp.status_code}, body={resp.text[:200]}")

                if resp.status_code == 200:
                    data = resp.json()
                    return data.get("code") == 0

            return False

        except Exception as e:
            print(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
            return False

    async def get_feishu_token(self) -> Optional[str]:
        """è·å–é£ä¹¦ access_token"""
        try:
            print(f"è·å– token: app_id={self.feishu_app_id[:10]}...")

            url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
            headers = {"Content-Type": "application/json"}
            payload = {
                "app_id": self.feishu_app_id,
                "app_secret": self.feishu_app_secret
            }

            async with httpx.AsyncClient() as client:
                resp = await client.post(url, headers=headers, json=payload, timeout=10)
                print(f"Token response status: {resp.status_code}")
                print(f"Token response: {resp.text[:200]}")

                if resp.status_code == 200:
                    data = resp.json()
                    print(f"Token data: {data}")
                    code = data.get("code")
                    print(f"Token code: {code}, type: {type(code)}")
                    if code == 0 or code == "0":
                        # token åœ¨é¡¶å±‚ï¼Œä¸åœ¨ data é‡Œ
                        token = data.get("tenant_access_token")
                        print(f"Returning token: {token[:20] if token else 'None'}...")
                        return token

        except Exception as e:
            print(f"è·å– token å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

        return None

    # ==================== è±†åŒ…æ’­å®¢ TTS åŠŸèƒ½ ====================

    async def generate_podcast(self, readings: List[Dict]) -> str:
        """ç”Ÿæˆæ’­å®¢éŸ³é¢‘"""
        try:
            # åˆå¹¶æ‰€æœ‰æ–‡ç« çš„åŸæ–‡å’Œæ€»ç»“ä½œä¸ºæ’­å®¢å†…å®¹
            podcast_text = self._prepare_podcast_text(readings)

            if not podcast_text:
                print("âš ï¸ æ²¡æœ‰å†…å®¹å¯ç”Ÿæˆæ’­å®¢")
                return ""

            print(f"ğŸ™ï¸ å¼€å§‹ç”Ÿæˆæ’­å®¢ï¼Œæ–‡æœ¬é•¿åº¦: {len(podcast_text)} å­—ç¬¦")

            # è°ƒç”¨è±†åŒ…æ’­å®¢APIï¼ˆä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼‰
            loop = asyncio.get_event_loop()
            audio_url = await loop.run_in_executor(
                None,
                self._generate_podcast_sync,
                podcast_text
            )

            if audio_url:
                print(f"âœ… æ’­å®¢ç”ŸæˆæˆåŠŸ: {audio_url}")
                return audio_url
            else:
                print("âš ï¸ æ’­å®¢ç”Ÿæˆå¤±è´¥")
                return ""

        except Exception as e:
            print(f"ç”Ÿæˆæ’­å®¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return ""

    def _generate_podcast_sync(self, text: str) -> str:
        """åŒæ­¥ç”Ÿæˆæ’­å®¢ï¼ˆä½¿ç”¨å®˜æ–¹ç¤ºä¾‹æ–¹å¼ï¼‰"""
        import websocket
        import json
        import struct
        import uuid
        import ssl
        import time
        import requests

        WS_URL = "wss://openspeech.bytedance.com/api/v3/sami/podcasttts"

        def build_msg(event, payload, session_id=None):
            """æ„å»º WebSocket æ¶ˆæ¯"""
            header = bytes([0x11, 0b00010100, 0x10, 0x00])  # type=1, flags=0100
            pl = payload.encode() if isinstance(payload, str) else payload
            parts = [struct.pack('>I', event)]
            if session_id is not None:
                sid = session_id.encode()[:12].ljust(12, b'\x00')
                parts.extend([struct.pack('>I', len(sid)), sid])
            parts.extend([struct.pack('>I', len(pl)), pl])
            return header + b''.join(parts)

        def parse_msg(data):
            """è§£æ WebSocket æ¶ˆæ¯"""
            if len(data) < 12:
                return None
            msg_type = (data[1] >> 4) & 0x0F
            event = struct.unpack('>I', data[4:8])[0]
            session_id_len = struct.unpack('>I', data[8:12])[0]
            offset = 12 + session_id_len
            payload_len = struct.unpack('>I', data[offset:offset+4])[0]
            payload = data[offset+4:offset+4+payload_len]
            try:
                payload = json.loads(payload.decode())
            except:
                pass
            return {'msg_type': msg_type, 'event': event, 'payload': payload}

        session_id = str(uuid.uuid4())

        try:
            # è¿æ¥ WebSocket
            ws = websocket.create_connection(
                WS_URL,
                header={
                    'X-Api-App-Id': self.volcengine_app_id,
                    'X-Api-Access-Key': self.volcengine_access_key,
                    'X-Api-Resource-Id': 'volc.service_type.10050',
                    'X-Api-App-Key': 'aGjiRDfUWi',
                },
                sslopt={"cert_reqs": ssl.CERT_NONE},
                timeout=180
            )

            # 1. StartConnection
            print("1ï¸âƒ£  StartConnection...")
            ws.send(build_msg(1, "{}"), opcode=websocket.ABNF.OPCODE_BINARY)
            msg = parse_msg(ws.recv())
            print(f"   âœ… ConnectionStarted (event={msg['event']})\n")

            # 2. StartSession - æ³¨æ„ event=100
            print("2ï¸âƒ£  StartSession...")
            params = {
                "input_id": f"news_{int(time.time())}",
                "input_text": text[:5000],  # é™åˆ¶é•¿åº¦
                "action": 0,
                "use_head_music": True,
                "use_tail_music": False,
                "audio_config": {"format": "mp3", "sample_rate": 24000},
                "speaker_info": {
                    "random_order": True,
                    "speakers": [
                        "zh_male_dayixiansheng_v2_saturn_bigtts",
                        "zh_female_mizaitongxue_v2_saturn_bigtts"
                    ]
                },
                "input_info": {"return_audio_url": True}
            }
            ws.send(build_msg(100, json.dumps(params), session_id), opcode=websocket.ABNF.OPCODE_BINARY)

            # 3. æ¥æ”¶æ’­å®¢æ•°æ®
            print("\n3ï¸âƒ£  æ­£åœ¨ç”Ÿæˆæ’­å®¢...\n")
            audio_url = None
            ws.settimeout(300)

            while True:
                try:
                    data = ws.recv()
                    msg = parse_msg(data)
                    if not msg:
                        continue

                    event = msg['event']
                    payload = msg['payload']

                    if event == 150:
                        print("âœ… SessionStarted\n")
                    elif event == 360:
                        round_id = payload.get('round_id', 0)
                        if round_id == -1:
                            print("ğŸµ ç‰‡å¤´éŸ³ä¹\n")
                        elif round_id == 9999:
                            print("ğŸµ ç‰‡å°¾éŸ³ä¹\n")
                    elif event == 363:
                        audio_url = payload.get('meta_info', {}).get('audio_url')
                        print(f"\nâœ… PodcastEnd! æ’­å®¢ç”Ÿæˆå®Œæˆ!")
                        break
                    elif event == 152:
                        print("âœ… SessionFinished")
                        break

                except websocket.WebSocketTimeoutException:
                    print("â±ï¸ è¶…æ—¶")
                    break
                except Exception as e:
                    print(f"âŒ é”™è¯¯: {e}")
                    break

            ws.close()

            # 4. è¿”å›å…¬ç½‘ URLï¼ˆä¸ä¸‹è½½åˆ°æœ¬åœ°ï¼ŒURL æœ‰æ•ˆæœŸ1å°æ—¶ï¼‰
            if audio_url:
                print(f"\nâœ… æ’­å®¢éŸ³é¢‘ URL: {audio_url[:80]}...")
                return audio_url
            else:
                print("\nâŒ æœªè·å–åˆ°éŸ³é¢‘URL")
                return ""

        except Exception as e:
            print(f"âŒ æ’­å®¢ç”Ÿæˆé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return ""

    def _prepare_podcast_text(self, readings: List[Dict]) -> str:
        """å‡†å¤‡æ’­å®¢æ–‡æœ¬"""
        lines = []
        lines.append("å¤§å®¶å¥½ï¼Œä»Šå¤©ä¸ºå¤§å®¶å¸¦æ¥æ–°é—»ç²¾è¯»ã€‚")

        for i, r in enumerate(readings, 1):
            title = r.get("title", "")
            source = r.get("source", "")
            content = r.get("content", "")[:2000]  # é™åˆ¶é•¿åº¦
            summary = r.get("summary", "")

            lines.append(f"ç¬¬{i}ç¯‡ï¼Œ{source}æŠ¥é“ï¼š")
            lines.append(f"æ ‡é¢˜ï¼š{title}")
            lines.append(f"åŸæ–‡å†…å®¹ï¼š{content}")
            if summary:
                lines.append(f"æ€»ç»“ï¼š{summary}")
            lines.append("")

        lines.append("ä»¥ä¸Šå°±æ˜¯ä»Šå¤©çš„æ–°é—»ç²¾è¯»ï¼Œæ„Ÿè°¢æ”¶å¬ã€‚")
        return "\n".join(lines)

    async def _call_doubao_podcast_api(self, text: str) -> str:
        """è°ƒç”¨è±†åŒ…æ’­å®¢TTS API"""
        import uuid
        import websockets
        from websockets.exceptions import ConnectionClosed

        ws_url = "wss://openspeech.bytedance.com/api/v3/sami/podcasttts"

        # ä½¿ç”¨ dict æ ¼å¼çš„ headers
        headers = {
            "X-Api-App-Id": self.volcengine_app_id,
            "X-Api-Access-Key": self.volcengine_access_key,
            "X-Api-Resource-Id": "volc.service_type.10050",
            "X-Api-App-Key": "aGjiRDfUWi",
            "X-Api-Request-Id": str(uuid.uuid4())
        }

        # æ„å»ºè¯·æ±‚å‚æ•°
        request_payload = {
            "input_id": f"news_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            "input_text": text[:8000],  # é™åˆ¶æ–‡æœ¬é•¿åº¦
            "action": 0,
            "use_head_music": True,
            "audio_params": {
                "format": "mp3",
                "sample_rate": 24000,
                "speech_rate": 0,
            },
            "speaker_info": {
                "random_order": True,
                "speakers": [
                    "zh_male_dayixiansheng_v2_saturn_bigtts",
                    "zh_female_mizaitongxue_v2_saturn_bigtts"
                ]
            },
            "aigc_watermark": False
        }

        try:
            async with websockets.connect(ws_url, additional_headers=headers) as ws:
                print("ğŸ”Œ WebSocket è¿æ¥æˆåŠŸ")

                # å‘é€ StartSession å¸§
                await self._send_start_session(ws, request_payload)

                # æ¥æ”¶å“åº”
                audio_url = await self._receive_podcast_response(ws)

                return audio_url

        except ConnectionClosed as e:
            print(f"WebSocket è¿æ¥å…³é—­: {e}")
            return ""
        except Exception as e:
            print(f"WebSocket é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return ""

    async def _send_start_session(self, ws, payload: dict):
        """å‘é€ StartSession å¸§"""
        import json

        session_id = "session_" + str(datetime.now().timestamp())
        payload_json = json.dumps(payload)

        # æ„å»ºäºŒè¿›åˆ¶å¸§
        # header: 4 bytes
        # [0] = 0b0001_0001 (version=1, header_size=1)
        # [1] = 0b1001_0100 (message_type=9, flags=4)
        # [2] = 0b0001_0000 (serialization=JSON, compression=none)
        # [3] = 0b0000_0000 (reserved)
        header = bytes([0x11, 0x94, 0x10, 0x00])

        # event type: StartSession = 1001 (éœ€è¦è½¬æ¢ä¸ºå¤§ç«¯ uint32)
        event_type = (1001).to_bytes(4, 'big')

        # session_id
        session_id_bytes = session_id.encode('utf-8')
        session_id_len = len(session_id_bytes).to_bytes(4, 'big')

        # payload
        payload_bytes = payload_json.encode('utf-8')
        payload_len = len(payload_bytes).to_bytes(4, 'big')

        # ç»„åˆå¸§
        frame = header + event_type + session_id_len + session_id_bytes + payload_len + payload_bytes

        await ws.send(frame)
        print(f"ğŸ“¤ å·²å‘é€ StartSession å¸§")

    async def _receive_podcast_response(self, ws) -> str:
        """æ¥æ”¶æ’­å®¢å“åº”"""
        audio_data = b""
        audio_url = ""

        while True:
            try:
                message = await ws.recv()

                if isinstance(message, bytes):
                    # è§£æäºŒè¿›åˆ¶å¸§
                    if len(message) < 8:
                        continue

                    # è§£æ header
                    byte0 = message[0]
                    byte1 = message[1]
                    byte2 = message[2]

                    version = (byte0 >> 4) & 0x0F
                    header_size = (byte0 & 0x0F) * 4
                    message_type = (byte1 >> 4) & 0x0F
                    flags = byte1 & 0x0F
                    serialization = (byte2 >> 4) & 0x0F
                    compression = byte2 & 0x0F

                    # è§£æ event number (4 bytes)
                    if len(message) >= 12:
                        event_num = int.from_bytes(message[4:8], 'big')

                        # è§£æ payload length
                        payload_len = int.from_bytes(message[8:12], 'big')

                        # è§£æ payload
                        if len(message) >= 12 + payload_len:
                            payload = message[12:12+payload_len]

                            # event 361: PodcastRoundResponse (éŸ³é¢‘)
                            # event 363: PodcastEnd (åŒ…å« audio_url)
                            if event_num == 363:
                                try:
                                    import json
                                    data = json.loads(payload.decode('utf-8'))
                                    meta_info = data.get("meta_info", {})
                                    audio_url = meta_info.get("audio_url", "")
                                    print(f"ğŸ“¥ æ”¶åˆ° audio_url: {audio_url[:50]}..." if audio_url else "æ²¡æœ‰ audio_url")
                                except:
                                    pass

                            # event 152: SessionFinished
                            elif event_num == 152:
                                print("ğŸ“¥ æ”¶åˆ° SessionFinished")
                                break

                elif isinstance(message, str):
                    # æ–‡æœ¬æ¶ˆæ¯
                    print(f"ğŸ“¥ æ”¶åˆ°æ–‡æœ¬æ¶ˆæ¯: {message[:100]}")

            except Exception as e:
                print(f"æ¥æ”¶æ¶ˆæ¯é”™è¯¯: {e}")
                break

        return audio_url

    async def _send_finish_session(self, ws):
        """å‘é€ FinishSession å¸§"""
        session_id = "session_" + str(datetime.now().timestamp())

        header = bytes([0x11, 0x94, 0x10, 0x00])
        event_type = (1002).to_bytes(4, 'big')  # FinishSession
        session_id_bytes = session_id.encode('utf-8')
        session_id_len = len(session_id_bytes).to_bytes(4, 'big')
        payload = b"{}"
        payload_len = len(payload).to_bytes(4, 'big')

        frame = header + event_type + session_id_len + session_id_bytes + payload_len + payload

        await ws.send(frame)
        print("ğŸ“¤ å·²å‘é€ FinishSession å¸§")

    async def _send_finish_connection(self, ws):
        """å‘é€ FinishConnection å¸§"""
        header = bytes([0x11, 0x94, 0x10, 0x00])
        event_type = (2).to_bytes(4, 'big')  # FinishConnection
        payload = b"{}"
        payload_len = len(payload).to_bytes(4, 'big')

        frame = header + event_type + payload_len + payload

        await ws.send(frame)
        print("ğŸ“¤ å·²å‘é€ FinishConnection å¸§")
