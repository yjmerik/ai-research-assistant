#!/usr/bin/env python3
"""
GitHub Actions è‡ªåŠ¨ç ”ç©¶æ”¶é›†è„šæœ¬

ç¯å¢ƒå˜é‡:
    FEISHU_APP_ID - é£ä¹¦åº”ç”¨ ID
    FEISHU_APP_SECRET - é£ä¹¦åº”ç”¨ Secret
    FEISHU_USER_OPEN_ID - æ¥æ”¶æ¶ˆæ¯çš„ç”¨æˆ·çš„ Open ID
    TOPIC - ç ”ç©¶ä¸»é¢˜ (é»˜è®¤: AI Agent)
    ARXIV_COUNT - arXiv è®ºæ–‡æ•°é‡ (é»˜è®¤: 10)
"""

import json
import os
import sys
import time
import urllib.request
import urllib.parse
from datetime import datetime
from xml.etree import ElementTree as ET
from typing import List, Dict, Any, Optional

try:
    import lark_oapi as lark
except ImportError:
    print("âŒ æœªå®‰è£… lark-oapi")
    sys.exit(1)


def log(message: str):
    """æ—¥å¿—è¾“å‡º"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] {message}")


def search_arxiv(query: str, max_results: int = 10) -> List[Dict]:
    """æœç´¢ arXiv è®ºæ–‡"""
    base_url = "http://export.arxiv.org/api/query"
    params = {
        "search_query": f"all:{query}",
        "start": 0,
        "max_results": max_results,
        "sortBy": "submittedDate",
        "sortOrder": "descending"
    }
    
    url = f"{base_url}?{urllib.parse.urlencode(params)}"
    
    try:
        log(f"ğŸ” æœç´¢ arXiv: {query}")
        with urllib.request.urlopen(url, timeout=60) as response:
            data = response.read()
        
        root = ET.fromstring(data)
        ns = {'atom': 'http://www.w3.org/2005/Atom', 'arxiv': 'http://arxiv.org/schemas/atom'}
        papers = []
        
        for entry in root.findall('atom:entry', ns):
            title_elem = entry.find('atom:title', ns)
            paper_title = title_elem.text.strip() if title_elem is not None else ""
            paper_title = ' '.join(paper_title.split())
            
            authors = []
            for author in entry.findall('atom:author', ns):
                name_elem = author.find('atom:name', ns)
                if name_elem is not None:
                    authors.append(name_elem.text)
            
            summary_elem = entry.find('atom:summary', ns)
            summary = summary_elem.text.strip() if summary_elem is not None else ""
            
            links = {}
            for link in entry.findall('atom:link', ns):
                rel = link.get('rel', '')
                href = link.get('href', '')
                if rel == 'alternate':
                    links['abstract'] = href
            
            published_elem = entry.find('atom:published', ns)
            published = published_elem.text[:10] if published_elem is not None else ""
            
            papers.append({
                'title': paper_title,
                'authors': authors[:3],
                'summary': summary[:400] + '...' if len(summary) > 400 else summary,
                'published': published,
                'url': links.get('abstract', '')
            })
        
        log(f"âœ… æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
        return papers
    
    except Exception as e:
        log(f"âŒ arXiv æœç´¢å¤±è´¥: {e}")
        return []


def generate_report(topic: str, papers: List[Dict]) -> str:
    """ç”Ÿæˆç ”ç©¶æŠ¥å‘Š"""
    today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
    
    lines = []
    lines.append(f"# {topic} - æ¯æ—¥ç ”ç©¶ç®€æŠ¥")
    lines.append("")
    lines.append(f"ğŸ“… **æ”¶é›†æ—¥æœŸ**: {today}")
    lines.append(f"ğŸ“Š **è®ºæ–‡æ•°é‡**: {len(papers)} ç¯‡")
    lines.append("")
    
    # æ•°æ®æ¦‚è§ˆ
    lines.append("## ğŸ“Š æ•°æ®æ¦‚è§ˆ")
    lines.append(f"- arXiv æœ€æ–°è®ºæ–‡: {len(papers)} ç¯‡")
    lines.append("")
    
    # è®ºæ–‡åˆ—è¡¨
    lines.append("## ğŸ“‘ æœ€æ–°è®ºæ–‡")
    lines.append("")
    
    if papers:
        for i, paper in enumerate(papers[:10], 1):
            lines.append(f"### {i}. {paper.get('title', 'N/A')}")
            
            authors = paper.get('authors', [])
            author_str = ', '.join(authors)
            lines.append(f"**ä½œè€…**: {author_str}")
            lines.append(f"**å‘å¸ƒæ—¶é—´**: {paper.get('published', 'N/A')}")
            
            summary = paper.get('summary', '')
            lines.append(f"**æ‘˜è¦**: {summary}")
            
            url = paper.get('url', '')
            if url:
                lines.append(f"**é“¾æ¥**: [{url}]({url})")
            
            lines.append("")
    else:
        lines.append("*æš‚æ— ç›¸å…³è®ºæ–‡*")
        lines.append("")
    
    # é¡µè„š
    lines.append("---")
    lines.append("")
    lines.append(f"*æœ¬æŠ¥å‘Šç”± GitHub Actions è‡ªåŠ¨ç”Ÿæˆ*")
    lines.append(f"*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
    
    return '\n'.join(lines)


def create_feishu_doc(client: lark.Client, title: str, content: str) -> Optional[str]:
    """åˆ›å»ºé£ä¹¦æ–‡æ¡£"""
    # åˆ›å»ºç©ºæ–‡æ¡£
    request = lark.BaseRequest.builder() \
        .http_method(lark.HttpMethod.POST) \
        .uri("/open-apis/docx/v1/documents") \
        .token_types({lark.AccessTokenType.TENANT}) \
        .body({"title": title}) \
        .build()
    
    response = client.request(request)
    
    if not response.success():
        try:
            err_data = json.loads(response.raw.content)
            log(f"âŒ åˆ›å»ºæ–‡æ¡£å¤±è´¥: {err_data}")
        except:
            log(f"âŒ åˆ›å»ºæ–‡æ¡£å¤±è´¥: {response.code}")
        return None
    
    try:
        resp_data = json.loads(response.raw.content)
        doc_id = resp_data.get("data", {}).get("document", {}).get("document_id")
    except:
        log("âŒ è§£æå“åº”å¤±è´¥")
        return None
    
    log(f"âœ… æ–‡æ¡£åˆ›å»ºæˆåŠŸ: {doc_id}")
    
    # è·å–é¡µé¢å— ID
    request = lark.BaseRequest.builder() \
        .http_method(lark.HttpMethod.GET) \
        .uri(f"/open-apis/docx/v1/documents/{doc_id}/blocks?page_size=1") \
        .token_types({lark.AccessTokenType.TENANT}) \
        .build()
    
    response = client.request(request)
    
    if not response.success():
        return doc_id
    
    try:
        resp_data = json.loads(response.raw.content)
        items = resp_data.get("data", {}).get("items", [])
        if not items:
            return doc_id
        page_block_id = items[0].get("block_id")
    except:
        return doc_id
    
    # è½¬æ¢å†…å®¹ä¸ºå—
    blocks = []
    for line in content.split('\n'):
        line = line.rstrip()
        if not line:
            continue
        
        if line.startswith('# '):
            blocks.append({
                "block_type": 3,
                "heading1": {"elements": [{"text_run": {"content": line[2:].strip()}}]}
            })
        elif line.startswith('## '):
            blocks.append({
                "block_type": 4,
                "heading2": {"elements": [{"text_run": {"content": line[3:].strip()}}]}
            })
        elif line.startswith('### '):
            blocks.append({
                "block_type": 5,
                "heading3": {"elements": [{"text_run": {"content": line[4:].strip()}}]}
            })
        elif line.startswith('- ') or line.startswith('* '):
            blocks.append({
                "block_type": 12,
                "bullet": {"elements": [{"text_run": {"content": line[2:].strip()}}]}
            })
        elif line.startswith('---'):
            blocks.append({"block_type": 16, "divider": {}})
        else:
            blocks.append({
                "block_type": 2,
                "text": {"elements": [{"text_run": {"content": line}}]}
            })
    
    # åˆ†æ‰¹æ·»åŠ å†…å®¹
    batch_size = 50
    for i in range(0, len(blocks), batch_size):
        batch = blocks[i:i + batch_size]
        
        request = lark.BaseRequest.builder() \
            .http_method(lark.HttpMethod.POST) \
            .uri(f"/open-apis/docx/v1/documents/{doc_id}/blocks/{page_block_id}/children") \
            .token_types({lark.AccessTokenType.TENANT}) \
            .body({"index": -1, "children": batch}) \
            .build()
        
        client.request(request)
        
        if i + batch_size < len(blocks):
            time.sleep(0.5)
    
    log(f"âœ… æ·»åŠ äº† {len(blocks)} ä¸ªå†…å®¹å—")
    return doc_id


def send_notification(client: lark.Client, user_id: str, topic: str, doc_id: str):
    """å‘é€æ¶ˆæ¯é€šçŸ¥"""
    doc_url = f"https://www.feishu.cn/docx/{doc_id}"
    
    # æ„å»ºå¡ç‰‡æ¶ˆæ¯
    message = {
        "config": {"wide_screen_mode": True},
        "header": {
            "title": {"tag": "plain_text", "content": "ğŸ“š æ¯æ—¥ç ”ç©¶ç®€æŠ¥"},
            "template": "green"
        },
        "elements": [
            {
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": f"**ã€Š{topic} - æ¯æ—¥ç ”ç©¶ç®€æŠ¥ã€‹** å·²ç”Ÿæˆ"
                }
            },
            {
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                }
            },
            {
                "tag": "action",
                "actions": [
                    {
                        "tag": "button",
                        "text": {"tag": "plain_text", "content": "ğŸ“– æŸ¥çœ‹æŠ¥å‘Š"},
                        "type": "primary",
                        "url": doc_url
                    }
                ]
            }
        ]
    }
    
    request = lark.BaseRequest.builder() \
        .http_method(lark.HttpMethod.POST) \
        .uri("/open-apis/im/v1/messages?receive_id_type=open_id") \
        .token_types({lark.AccessTokenType.TENANT}) \
        .body({
            "receive_id": user_id,
            "msg_type": "interactive",
            "content": json.dumps(message)
        }) \
        .build()
    
    response = client.request(request)
    
    if response.success():
        log("âœ… æ¶ˆæ¯é€šçŸ¥å·²å‘é€")
    else:
        try:
            err_data = json.loads(response.raw.content)
            log(f"âš ï¸  å‘é€æ¶ˆæ¯å¤±è´¥: {err_data}")
        except:
            log(f"âš ï¸  å‘é€æ¶ˆæ¯å¤±è´¥: {response.code}")


def main():
    log("=" * 70)
    log("ğŸ¤– GitHub Actions - è‡ªåŠ¨ç ”ç©¶æ”¶é›†")
    log("=" * 70)
    
    # è¯»å–ç¯å¢ƒå˜é‡
    app_id = os.environ.get('FEISHU_APP_ID')
    app_secret = os.environ.get('FEISHU_APP_SECRET')
    user_id = os.environ.get('FEISHU_USER_OPEN_ID')
    topic = os.environ.get('TOPIC', 'AI Agent')
    arxiv_count = int(os.environ.get('ARXIV_COUNT', '10'))
    
    log(f"ğŸ“Œ ä¸»é¢˜: {topic}")
    log(f"ğŸ“Š æ•°é‡: {arxiv_count}")
    log("")
    
    # æ£€æŸ¥å‡­è¯
    if not app_id or not app_secret:
        log("âŒ æœªæ‰¾åˆ°é£ä¹¦åº”ç”¨å‡­è¯")
        sys.exit(1)
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = lark.Client.builder() \
        .app_id(app_id) \
        .app_secret(app_secret) \
        .log_level(lark.LogLevel.ERROR) \
        .build()
    
    # 1. æœç´¢ arXiv
    papers = search_arxiv(topic, arxiv_count)
    
    # 2. ç”ŸæˆæŠ¥å‘Š
    log("ğŸ“ ç”Ÿæˆç ”ç©¶æŠ¥å‘Š...")
    today_str = datetime.now().strftime('%Y%m%d')
    report = generate_report(topic, papers)
    doc_title = f"{topic} - æ¯æ—¥ç ”ç©¶ç®€æŠ¥ {today_str}"
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶ï¼ˆç”¨äº GitHub Actions ä¸Šä¼ ï¼‰
    with open('research_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    log("âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ° research_report.md")
    
    # 3. åˆ›å»ºé£ä¹¦æ–‡æ¡£
    log("ğŸ“„ åˆ›å»ºé£ä¹¦æ–‡æ¡£...")
    doc_id = create_feishu_doc(client, doc_title, report)
    
    if doc_id:
        doc_url = f"https://www.feishu.cn/docx/{doc_id}"
        log(f"âœ… æ–‡æ¡£åˆ›å»ºæˆåŠŸ: {doc_url}")
        
        # ä¿å­˜æ–‡æ¡£ä¿¡æ¯
        with open('doc_info.json', 'w') as f:
            json.dump({'doc_id': doc_id, 'doc_url': doc_url, 'title': doc_title}, f)
        
        # 4. å‘é€é€šçŸ¥
        if user_id:
            log("ğŸ“¤ å‘é€æ¶ˆæ¯é€šçŸ¥...")
            send_notification(client, user_id, topic, doc_id)
        else:
            log("âš ï¸  æœªè®¾ç½®ç”¨æˆ· Open IDï¼Œè·³è¿‡æ¶ˆæ¯é€šçŸ¥")
    else:
        log("âŒ æ–‡æ¡£åˆ›å»ºå¤±è´¥")
        sys.exit(1)
    
    log("")
    log("=" * 70)
    log("âœ… ä»»åŠ¡å®Œæˆ")
    log("=" * 70)


if __name__ == '__main__':
    main()
